receivers:
  otlp:
    protocols:
      grpc:

processors:
  batch:
    # batch metrics before sending to reduce API usage
    send_batch_max_size: 200
    send_batch_size: 200
    timeout: 5s

  memory_limiter:
    # drop metrics if memory usage gets too high
    check_interval: 1s
    limit_percentage: 65
    spike_limit_percentage: 20

  resourcedetection:
    detectors: [env, gcp]
    timeout: 2s
    override: false

exporters:
  googlecloud:
    log:
      default_log_name: backend
  googlemanagedprometheus:

extensions:
  health_check:

service:
  extensions: [health_check]
  pipelines:
    traces:
      receivers: [otlp]
      processors: [resourcedetection]
      exporters: [googlecloud]
    logs:
      receivers: [otlp]
      processors: [resourcedetection]
      exporters: [googlecloud]
    metrics:
      receivers: [otlp]
      processors: [resourcedetection]
      exporters: [googlemanagedprometheus]